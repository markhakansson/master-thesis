The goal of this thesis was to explore the possibilities and limitations of
developing a tool to automatically calculate the WRCT for user tasks in an
RTIC application.

With minimal changes to the RTIC application, RAUK uses KLEE to generate test
vectors in order to target all execution paths in the user tasks. Then the
execution times for each test vector can be replayed and measured on the target
hardware. Using these measurements, a schedulability analysis check can be
performed following the Stack Resource Policy and the fixed-priority preemptive
scheduling theory that RTIC adheres to, in order to check whether the system is
schedulable or not.

The tool was tested on a simple RTIC application which toggled an LED on the
target development board and could be interrupted externally via a button
on the board. Using RAUK the tool found one arithmetic error when the
application was executed without any optimizations and given some extra input,
the tool could determine whether the system was schedulable or not by comparing
the calculated WCRT for each task with their respective deadlines and that the
worst-cast total system load did not exceed 100\%.

With the current limitations RAUK adds some constant overhead to the measured
execution time results. For tasks with generally longer execution times, this
overhead will result in a small fraction of more cycles in the resulted
measurements. But for tasks with generally short execution times the resulted
measurements can be many times longer than the actual execution time.

% seamless Rust ecosystem integration
% minimal changes to source code
% support for IO
% included schedulability analysis
% latest RTIC version
The work in this thesis was inspired by the previous work by~\cite{lindner} for
WCET analysis using KLEE. The approach chosen for WCET analysis in RAUK uses
the same method presented in their paper. Compared to their solution, the WCET
analysis in RAUK has support to analyze I/O accesses such as hardware
peripherals. RAUK also has a seamless integration with the Rust ecosystem, and
thus requires very minimal changes to the application source code and external
tools in order to execute the analysis. In comparison to the test bench
in~\cite{lindner}, which was scripted in Python and required external tools
such as GDB and required many changes to the application in order to execute.
In RAUK the schedulability analysis has been included in order to actually use
the response-time analysis results from the WCET estimations.

As of writing this, RAUK is still a proof-of-concept tool and is not yet suited
for reliably analyzing production ready software. The flaws presented in this thesis
needs to be remedied before that. Because RAUK is fully open-source, the work
that has been accomplished here will hopefully serve as a good base for a next
revision of this tool or a completely new tool.

\section{Future work}
Some solutions to the limitations and problems discussed in Chapter~\ref{chapter:discussion} 
will be addressed here. Which are also recommendations for fixes in the next or a future iteration of RAUK\@.

\textbf{Better test vectors:} The problem with certain code sections being
optimized out when generating test vectors with compiler optimizations enabled
can be easily fixed by introducing side effects in the aforementioned
functions. In the current implementation when generating tests, the ARM related
instructions do nothing in order to make the application run on the Linux
x86--64 toolchain. The compiler notices this if it is told to optimize the code
and will simply remove these sections instead of keeping them in the built
binary.

Side effects can be added inside these instructions by e.g.\ do a volatile
read to a memory address inside them. By reading or writing directly to memory
addresses, the Rust compiler will not optimize out that specific code sections
when the application is built with optimizations enabled. This is because the
compiler is unable to determine if volatile memory accesses have side effects
or not.

In this thesis the assumption that KLEE generates test vectors for the longest
path was not proven. To combat this, the symbolic execution tool used in RAUK
would have to run on the hardware instructions instead of on LLVM IR\@. KLEE does
not support this however and only runs on top of LLVM IR\@. Or alternatively one
could investigate how LLVM IR is translated into ARM instructions to see what
relations there are. E.g.\ to see if some LLVM instructions are translated to
fewer or more equivalent ARM instructions. Using this information it could
be possible to determine whether the test vectors generated in practice
actually contain the longest path or not on the final binary for the target
hardware.

\textbf{Reduce measuring overhead:} There were some overhead on the measurement
results caused by the current implementation of the breakpoint instruction.
There is a theoretical fix for this problem on the stable release channel in
the Cortex-M library by adding some additional flags to the Rust compiler and
enabling linker plugin based LTO (link time optimization) when building the
replay harness. Then the final code optimizations will be performed during
linking and not before. This could reduce the overhead drastically by inlining
the instructions. 

This was tested very hastily without any attention to any details, but did not
produce any notable changes. There might have been some missing compilations
flags and other settings that needs to be set in order to optimize it
correctly. Or maybe some modifications needs to be made on the custom fork of
the Cortex-M library for it to work. Either way, this is considered a high
priority to fix in the next iteration of RAUK\@.

\textbf{Compare with other tools:} Unfortunately the schedulability analysis
was only executed with RAUK and no other available tools were tested. A
comparison with other tools would have been valuable to determine whether the
results from the different tools would differ or not. 

\textbf{Easier maintainability:} To make this tool viable for continued support
in the future, the tool would benefit if many of the libraries in the RTIC and
Cortex-M ecosystem for Rust were more modularized. Many of the forked libraries
are of larger libraries and only changes small parts of them. If only smaller
parts could be forked it would significantly simplify the process of
maintaining them. There currently is work being made on modularizing the RTIC
library itself, and then the harnesses needed by RAUK could be easily extended
in the RTIC library without the need of maintaining the rest of the components.

\textbf{Full RTIC support:} the current implementation of RAUK only supports
a subset of all features in the RTIC framework. Support for analyzing complex
resource types (such as data structures) and full support for software tasks
should also be included in the measuring stage. The current approach for the APIs
used by software tasks to schedule and spawn tasks at certain times using
monotonic timers, is to just ignore the implementation completely during
measurement, thus the result will not comparable to the actual execution time.
