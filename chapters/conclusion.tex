The goal of this thesis was to explore the possibilities and limitations of
developing a tool to automatically calculate the WCRT for user tasks in an
RTIC application, to verify the application's schedulability.

With minimal changes to the RTIC application source code, RAUK uses KLEE to
generate test vectors in order to target all execution paths in the user tasks.
Then each test vector can be replayed and the execution times measured on the
target hardware. Using these measurements, a schedulability analysis can be
performed following the Stack Resource Policy and the fixed-priority preemptive
scheduling theory that RTIC adheres to, in order to check whether the system is
schedulable or not.

% reference previous chapters
As a consequence, by using KLEE there is also the additional benefit of
generating test cases for execution paths that result in the program aborting.
E.g.\ errors such as accessing indexes in an array that is out of bounds, or
arithmetic overflow. Therefore, RAUK is not only limited to perform
schedulability analysis on the RTIC application, but can also be used for
generating test cases to verify that there is no such abort errors present in
the application, improving reliability of the program.

% reference previous chapters
The tool was tested on a simple RTIC application which toggled an LED on the
target development board on and off, where the LED could be interrupted
externally via a button on the board. Using RAUK, the tool found one arithmetic
error when the application was executed without any optimizations and given
some extra input, the tool could determine that the system was schedulable by
comparing the calculated WCRT for each task with their respective deadlines and
that the worst-cast total system load did not exceed 100\%.

% reference previous chapters
With the current limitations, RAUK adds some constant overhead to the measured
execution time results. For tasks with generally longer execution times, this
overhead will result in a small fraction of more cycles in the resulting
measurements. But for tasks with typically short execution times, the resulting
measurements can be many times longer than the actual execution time.

The work in this thesis was inspired by the previous work by~\cite{lindner} for
WCET analysis using KLEE\@. The approach chosen for WCET analysis in RAUK uses
the same method as presented in their paper. Compared to their solution, the WCET
analysis in RAUK has support for analyzing I/O accesses such as hardware
peripherals. RAUK also has a seamless integration with the Rust ecosystem,
requiring minimal changes to the application source code and requiring no
external tools in order to execute the analysis. In comparison to the test
bench in~\cite{lindner}, which was scripted in Python and required external
tools such as GDB and required substantial alterations to the application in
order to execute. In RAUK the schedulability analyzer has been included in
order to actually use the response-time analysis results from the WCET
estimations.

As of writing this, RAUK is very much a proof-of-concept tool. Since it
currently only works on simple RTIC applications, is not yet suited for
reliably analyzing larger and more complex software. The flaws presented in
this thesis needs to be remedied before that, and possible solutions to the
same flaws are discussed in Section~\ref{chapter:futurework}.

We think that a complete tool that can easily integrate with an RTIC
application for finding program errors, execute a WCET estimation by executing
tasks on the actual hardware in order to verify the application's
schedulability would certainly be useful for RTIC application developers. As
currently, there are no available tools for this in this area in embedded Rust
nor for the RTIC framework. Because RAUK is fully open-source software, the
work that has been accomplished here can hopefully serve as a good starting
point for a next revision of this tool, or the inspiration for a completely new
tool following the same approach.

\section{Future work}
\label{chapter:futurework}
Some solutions to the limitations and problems discussed in
Chapter~\ref{chapter:discussion} will be addressed here. Which are also
suggestions for fixes in the next or a future iteration of RAUK\@.

\textbf{Better test vectors:} The problem with certain code sections being
optimized out when generating test vectors with compiler optimizations enabled
can be easily fixed by introducing side effects in the aforementioned
functions. In the current implementation when generating tests, the ARM related
instructions do nothing in order to make the application run on the Linux
x86--64 toolchain. The compiler notices this if it is told to optimize the code
and will simply remove these sections instead of keeping them in the built
binary.

Side effects can be added inside these instructions by e.g.,\ do a volatile
read to a memory address inside them. By reading or writing directly to memory
addresses, the Rust compiler will not optimize out that specific code sections
when the application is built with optimizations enabled. This is because the
compiler is unable to determine if volatile memory accesses have side effects
or not.

In this thesis, the assumption that KLEE generates test vectors for the longest
path was not proven. To combat this, the symbolic execution tool used in RAUK
would have to run on the hardware instructions instead of on LLVM IR\@. KLEE does
not support this however and only runs on top of LLVM IR\@. Or alternatively, one
could investigate how LLVM IR is translated into ARM instructions to see what
relations there are. E.g.,\ to see if some LLVM instructions are translated to
fewer or more equivalent ARM instructions. Using this information, it could
be possible to determine whether the test vectors generated in practice
actually contain the longest path or not on the final binary for the target
hardware.

\textbf{Reduce measuring overhead:} There were some overhead on the measurement
results caused by the current implementation of the breakpoint instruction.
There is a theoretical fix for this problem on the stable release channel for
Rust version 1.51 in the Cortex-M library by adding some additional flags to
the Rust compiler and enabling linker plugin based LTO (link time optimization)
when building the replay harness. Then the final code optimizations will be
performed during linking and not before. This could reduce the overhead
drastically by inlining the instructions. 

This was tested very hastily without any attention to any details, but did not
produce any notable changes. There might have been some missing compilation
flags and other settings that needs to be set in order to optimize it
correctly. Or maybe some modifications need to be made on the custom fork of
the Cortex-M library for it to work. Either way, this is considered a high
priority to fix in the next iteration of RAUK\@.

\textbf{Compare with other tools:} Unfortunately, the schedulability analysis
was only executed with RAUK and no other available tools were tested. A
comparison with other tools would have been valuable to determine whether the
results from the different tools would differ or not. 

\textbf{Easier maintainability:} To make this tool viable for continued support
in the future, the tool would benefit if many of the libraries in the RTIC and
Cortex-M ecosystem for Rust were more modular. Many of the forked libraries
are of larger libraries and only changes small parts of them. If only smaller
parts could be forked, it would significantly simplify the process of
maintaining them. There currently is work being made on modularizing the RTIC
library itself, and then the harnesses needed by RAUK could be easily extended
in the RTIC library without the need of maintaining the rest of the components.

\textbf{Full RTIC 1.0 support:} the current implementation of RAUK only supports
a subset of all features in the RTIC framework. Support for analyzing complex
resource types (such as data structures) and full support for software tasks
should also be included in the measuring stage. The current approach for the APIs
used by software tasks to schedule and spawn tasks at certain times using
monotonic timers, is to just ignore the implementation completely during
measurement, thus the result will not comparable to the actual execution time.
Since there is not a single monotonic timer implementation for RTIC, the
behavior of the monotonic API should be characterized separately in a way such
that RAUK can actually include it in its analysis.

