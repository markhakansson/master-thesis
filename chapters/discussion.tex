In this chapter the evaluation in the previous chapter will be reviewed
and the problems that were found during the evaluation.

\section{Analysis of test vectors}
When comparing the generated test vectors from KLEE for both unoptimized and
optimized code in Tables \ref{tab:evaldebugtestsbutton},
\ref{tab:evaldebugteststoggle} and \ref{tab:evalreleasetestsbutton},
\ref{tab:evalreleaseteststoggle} with the task source code in Listings
\ref{lst:evalbutton}, \ref{lst:evaltoggle}, it can be seen that KLEE manages to
hit all branches in both tasks without optimizations. With optimizations
enabled however, all branches are reached in the \texttt{toggle\_led} function
but one branch is completely missed inside the \texttt{button\_click} function.
Where the variable \texttt{value} is compared to the value $123456789$ in
Listing \ref{lst:evalbutton}, line 17.

Since KLEE runs on the Linux x86-64 toolchain, RAUK will build the test harness
for the same toolchain. Thus the ARM and Cortex-M specific functions will have
no side effects. I.e. such functions will not affect the system or application
in any way. When optimizations are enabled the compiler will find the branches
and code without side effects and remove them from its output. Since the
branches are no longer included in the LLVM IR, KLEE will obviously not
produce test vectors for non-existent paths.

Another problem with the test vectors, that was mentioned in the paper by
Lindner et al.\ \cite{lindner} which is also applicable in this thesis, is that
the test vectors generated by KLEE will not necessarily hit the longest paths
in the actual application running on the hardware. Since KLEE runs on LLVM IR
and can target all execution paths in it, some of the generated tests will
in turn also target the longest paths in it. But when translating from LLVM
IR to actual hardware instructions, the execution paths in the final binary
can differ from the LLVM IR.

On another note, it can be seen in Table \ref{tab:evaldebugtestsbuttonerror}
that KLEE generated a test vector which will result in the program crashing.
Which was the value 255 on the resource \texttt{shared\_u8}. Looking at the
source code in Listing \ref{lst:evalbutton}, an increment is made on that
resource and since the resource is only a byte large an increment on 255 will
result in an arithmetic overflow. This does not happen with release
optimizations however, as the compiler will simple let the increment wrap
around by starting at 0 instead of crashing. This demonstrates that RAUK
can not only be used for schedulability analysis, but also for analyzing
certain possible errors in the application.

\section{Analysis of measurement results}
When comparing the measurement results from the RAUK tool with the manually
traced results in Table \ref{tab:evaldebugmeasure} and Table
\ref{tab:evalreleasemeasure} for no optimizations and optimizations
respectively. It can be seen that there is some overhead by using RAUK. Which
for most of the tests generated are about 400 extra clock cycles compared to
the manually traced results. This is mostly due to the overhead of the software
breakpoints that are used in the replay harness and the way assembly
instructions using the \texttt{cortex-m} library (which the software
breakpoints inserted are originated from) are currently implemented in the
stable release channel of the Rust language.

Since Rust currently does not support inline assembly in the stable release
channel, the library for the Cortex-M assembly instructions uses external
assembly. Basically the assembly instructions are called by library specific
functions in the source code which in turn calls external functions that are
already pre-compiled and linked together with the binary after compilation of
the application. Also in order to call the breakpoint instructions with values,
used to denote what type of breakpoint it is in the replay harness, there will
be some additional overhead with the current implementation. The overhead for a
single breakpoint is on average around 20 cycles. There are three breakpoints
set for each task and resource claim in the replay harness and a single one for
hardware accesses.

\section{Analysis of schedulability results}
The schedulability test in RAUK using the generated test vectors has been
implemented according to the theory in Section \ref{theory:schedulability}.
With the task information provided as in Table \ref{tab:evalschedtasks} the
system can be tested for different values depending on the requirements. One
such case could be how many times can the button be pressed if the LED toggles
at 60 Hz and still be schedulable.

In Table \ref{tab:evalscheddebug} the WCET in the schedulability results for no
optimizations differ a few cycles from the worst measured ET in Tables
\ref{tab:evaldebugteststoggle}, \ref{tab:evaldebugtestsbutton}. This is most
likely an error during the collection of the tests and measurement data. The
WCET in the schedulability results with optimizations in Table
\ref{tab:evalschedrelease} do correspond with the worst measured ET in Tables
\ref{tab:evalreleaseteststoggle}, \ref{tab:evalreleasetestsbutton}.

Both schedulability analyses (for unoptimized and optimized code) passes the
schedulability test as the calculated WCRT for all tasks are less than
the deadlines defined in Table \ref{tab:evalschedtasks} and the worst-case
system load are less than 100\%.

Unfortunately the schedulability analysis was only executed with RAUK and no
other available tools were tested. A comparison with other tools would have
been valuable to determine whether the results from the different tools would
differ or not. If there would have been more time to allocate, this is an
area that would have been interesting to research further.

\section{On maintainability of RAUK}
One of the bigger difficulties during the work of this thesis has been
maintaining the tool and keeping it up to date to the upstream version of RTIC.
Due to the many custom forks that are used in order to generate tests and
measure the execution times by RAUK, the RAUK tool is very prone to break or
not function as intended should a dependency version in the RTIC application
(that is to be tested) differ from the ones that are maintained to work with
RAUK. Even updates on the Rust compiler can break the test generation phase
with KLEE. As the compiler in some versions translates the Rust source code to
experimental LLVM instructions which KLEE does not support.
