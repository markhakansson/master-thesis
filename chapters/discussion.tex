% Discuss how the problem definition was solved and the results

% Some problems
% * labelling the output data is tricky
% x overhead by using breakpoint function rather than inline assembly
% * keeping the tool up to date with latest RTIC/Rust/forks
% x KLEE: LLVM IR is not equivalent to ARM insructions
% x No side effects -> instructions left out of LLVM IR
\section{Analysis of test vectors}
When comparing the generated test vectors from KLEE for both unoptimized and
optimized code in Tables \ref{tab:evaldebugtestsbutton},
\ref{tab:evaldebugteststoggle} and \ref{tab:evalreleasetestsbutton},
\ref{tab:evalreleaseteststoggle} with the task source code in Listings
\ref{lst:evalbutton}, \ref{lst:evaltoggle}, it can be seen that KLEE manages to
hit all branches in both tasks without optimizations. With optimizations
enabled however, all branches are reached in the \texttt{toggle\_led} function
but one branch is completely missed inside the \texttt{button\_click} function.
Where the variable \texttt{value} is compared to the value $123456789$ in
Listing \ref{lst:evalbutton}, line 17.

Since KLEE runs on the Linux x86-64 toolchain, RAUK will build the test harness
for the same toolchain. Thus the ARM and Cortex-M specific functions will have
no side effects. I.e. such functions will not affect the system or application
in any way. When optimizations are enabled the compiler will find the branches
and code without side effects and remove them from its output. Since the
branches are no longer included in the LLVM IR, KLEE will obviously not
produce test vectors for non-existent paths.

This problem can be easily fixed by introducing side effects in the
aforementioned functions by e.g.\ do a volatile read to a memory address
inside them. By reading by writing directly to memory addresses, the Rust
compiler will not optimize out that specific code sections when the application
is built with optimizations enabled. This is because the compiler is unable to
determine if volatile memory accesses have side effects or not.

Another problem with the test vectors, that was mentioned in the paper by
Lindner et al.\ \cite{lindner} which is also applicable in this thesis, is that
the test vectors generated by KLEE will not necessarily hit the longest paths
in the actual application running on the hardware. Since KLEE runs on LLVM IR
and can target all execution paths in it, some of the generated tests will
in turn also target the longest paths in it. But when translating from LLVM
IR to actual hardware instructions, the execution paths in the final binary
can differ from the LLVM IR. To combat this, the symbolic execution tool used in
RAUK would have to run on the hardware instructions instead of on LLVM IR. KLEE
does not support this however and only runs on top of LLVM.

\section{Analysis of measurement results}
When comparing the measurement results from the RAUK tool with the manually
traced results in Table \ref{tab:evaldebugmeasure} and Table
\ref{tab:evalreleasemeasure} for no optimizations and optimizations
respectively. It can be seen that there is some overhead by using RAUK. Which
for most of the tests generated are about 400 extra clock cycles compared to
the manually trace results. This is mostly due to the breakpoints that are used
in the replay harness and the way assembly instructions using the
\texttt{cortex-m} library are currently implemented in the stable release
channel of the Rust language.

Since Rust currently does not support inline assembly in the stable release
channel, the library for the Cortex-M assembly instructions uses external
assembly. Basically the assembly instructions are called by library specific
functions in the source code which in turn calls external functions that are
already pre-compiled and linked together with the binary after compilation of
the application. Also in order to call the breakpoint instructions with values,
used to denote what type of breakpoint it is in the replay harness, there will
be some additional overhead with the current implementation. The overhead for a
single breakpoint is on average around 20 cycles. There are three breakpoints
set for each task and resource claim in the replay harness and a single one for
hardware accesses.

Although there is a fix for this problem on the stable release channel in the
Cortex-M library by adding some additional flags to compiler, it was not
tested due to time constraints.

\section{Analysis of schedulability results}


\section{On maintainability}
